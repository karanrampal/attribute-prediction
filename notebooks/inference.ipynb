{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d33c952c-16cd-4e2d-b36b-bc495a9a21ee",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c0b32-1504-4d78-b22b-38520ce1bc70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "from typing import Callable, Optional, Tuple\n",
    "sys.path.insert(0, \"../src\")\n",
    "\n",
    "import gcsfs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, PrecisionRecallDisplay, precision_recall_curve\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as tvt\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from model.net import avg_acc_gpu, avg_f1_score_gpu, confusion_matrix, Net\n",
    "from utils.utils import load_checkpoint, Params\n",
    "\n",
    "rng = default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a878eda-df67-43d3-a5c4-8edae59dc5b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gfs = gcsfs.GCSFileSystem(project=\"airesearch-1409\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeffd00-7c55-45cd-9368-8ec6841d5852",
   "metadata": {},
   "source": [
    "# Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f2ecc4-86f9-4935-bfb8-a564f63cb7ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = \"gs://hm_images/\"\n",
    "model_path = \"../experiments/base_model\"\n",
    "img_path = \"images\"\n",
    "annotation_path = \"annotations\"\n",
    "\n",
    "thr = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a614e30-5dac-4158-b952-1162a1c60d67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = Params(\n",
    "    {\n",
    "        \"num_classes\":72,\n",
    "        \"dropout\": 0.5,\n",
    "        \"height\": 256,\n",
    "        \"width\": 256,\n",
    "        \"crop\": 224,\n",
    "        \"data_dir\": root,\n",
    "        \"batch_size\": 128,\n",
    "        \"cuda\": torch.cuda.is_available(),\n",
    "        \"device\": \"cuda:0\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf873e9-a874-4615-ae8f-0ff364ea9bb3",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa9daef-91c6-41fb-9336-17e0d97d1567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    \"\"\"Custom class for Attribute prediction dataset\n",
    "    Args:\n",
    "        root: Directory containing the dataset\n",
    "        file_path: Path of the train/val/test file relative to the root\n",
    "        transforms: Data augmentation to be done\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        file_path: str,\n",
    "        gfs: gcsfs.core.GCSFileSystem,\n",
    "        transforms: Optional[Callable] = None,\n",
    "    ) -> None:\n",
    "        self.root = root\n",
    "        self.data = pd.read_csv(os.path.join(root, file_path))\n",
    "        self.transforms = transforms\n",
    "        self.gfs = gfs\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Get an item from the dataset given the index idx\"\"\"\n",
    "        row = self.data.iloc[idx]\n",
    "\n",
    "        im_name = row[\"path\"]\n",
    "        im_path = os.path.join(self.root, \"images\", im_name)\n",
    "        img = Image.open(io.BytesIO(self.gfs.open(im_path).read())).convert(\"RGB\")\n",
    "\n",
    "        labels = torch.as_tensor(row[1:], dtype=torch.float32)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, labels\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Length of the dataset\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "transform = tvt.Compose(\n",
    "    [\n",
    "        tvt.Resize((params.height, params.width)),\n",
    "        tvt.CenterCrop(params.crop),\n",
    "        tvt.ToTensor(),\n",
    "        tvt.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d77b4-9a00-4539-a659-09e91bc8f2c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ds = TestDataset(params.data_dir, \"annotations/test.csv\", gfs, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbd7751-6c20-4aa7-8694-2acfde92dd16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = rng.integers(len(test_ds) - params.batch_size - 1)\n",
    "inp_data, labels = [], []\n",
    "for i in trange(start, start + params.batch_size):\n",
    "    img, label = test_ds[i]\n",
    "    inp_data.append(img)\n",
    "    labels.append(label)\n",
    "inp_data = torch.stack(inp_data, 0)\n",
    "labels = torch.stack(labels, 0)\n",
    "\n",
    "print(inp_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be8bc14-1b0d-4d27-861d-172ac2b8bbc2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(root, \"annotations/test.csv\"))\n",
    "cols = data.columns.tolist()[1:]\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4c4383-7923-419d-acc0-0d86c015a91d",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efd9c18-2d07-4c9a-9446-0ff91302a1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Net(params)\n",
    "load_checkpoint(os.path.join(model_path, \"best.pth.tar\"), model);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c1e512-ae69-48ce-8e60-d25587b8eac7",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ea6c9-9ae8-4396-89e6-35758d45761b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "if params.cuda:\n",
    "    model.to(params.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    if params.cuda:\n",
    "        inp_data = inp_data.to(params.device)\n",
    "        labels = labels.to(params.device)\n",
    "    output = model(inp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34865f2-75d4-4361-b24e-1fd7899e0a88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_cpu = labels.cpu().numpy()\n",
    "preds = torch.sigmoid(output).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848174c4-0767-417c-b49c-1f732219d03c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mat = confusion_matrix(output, labels, thr).numpy()\n",
    "\n",
    "print(f\"Avg. Accuracy: {avg_acc_gpu(output, labels, thr):.3f} @ {thr}\")\n",
    "print(f\"Avg. F1 score: {avg_f1_score_gpu(output, labels, thr):.3f} @ {thr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add9c394-adf6-46a2-b28f-904cd50e4073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ConfusionMatrixDisplay(mat[idx]).plot(ax=ax[0], cmap=\"Blues\");\n",
    "\n",
    "prec, recall, _ = precision_recall_curve(\n",
    "    labels_cpu[:, idx], preds[:, idx]\n",
    ")\n",
    "PrecisionRecallDisplay(prec, recall).plot(ax=ax[1])\n",
    "fig.suptitle(f\"{cols[idx]}\", fontsize=16)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22e3c33-2bb1-4bdb-95c6-d5adceee10e5",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c493af-7525-44ed-a2fd-e88e2aee3883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_imgs = inp_data.cpu().numpy() * np.asarray([0.229, 0.224, 0.225]).reshape(1, -1, 1, 1)\n",
    "test_imgs += np.asarray([0.485, 0.456, 0.406]).reshape(1, -1, 1, 1)\n",
    "test_imgs = test_imgs.clip(0.0, 1.0)\n",
    "\n",
    "col_names = np.asarray(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e578ada9-e982-47ab-b83d-fdd0c69f318c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = rng.integers(params.batch_size)\n",
    "\n",
    "plt.imshow(test_imgs[i, ...].transpose(1, 2, 0))\n",
    "print(f\"Labels: {col_names[labels_cpu[i].astype(bool)]}\")\n",
    "print(f\"Predictions: {col_names[preds[i] > thr]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8701db-3b93-48d2-814f-2388d72a8879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "cv3d-env",
   "name": "pytorch-gpu.1-13.m106",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m106"
  },
  "kernelspec": {
   "display_name": "cv3d-env",
   "language": "python",
   "name": "cv3d-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
